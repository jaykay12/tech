---
layout: post
title: Basics of Apache Spark
categories: [Data Engineering]
---

> Unified analytics engine for large-scale real-time & batch data processing.

![spark](../assets/images/SPARK-1.png)

Main strengths of Apache Spark:
- **Speed**:
  - Run workloads 100x faster as compared to Hadoop.
  - Achieves high performance for both batch and streaming data.
- **Ease of Use**:
  - Write applications quickly in Java, Scala, Python, R, and SQL.
  - Can be used interactively from the Scala, Python, R, and SQL shells too.
- **Generality**:
  - Combine SQL, streaming, and complex analytics together.
  - It powers a stack of libraries including SQL and DataFrames, MLlib for machine learning, GraphX, and Spark Streaming.
- **Runs Everywhere**:
  - Spark runs on Hadoop, Apache Mesos, Kubernetes, standalone, or in the cloud.
  - It can access diverse data sources like HDFS, Alluxio, Apache Cassandra, Apache HBase, Apache Hive etc.


# Introduction to Apache Spark

![spark-history](../assets/images/SPARK-2.png)

### Features of Apache Spark
![spark-features](../assets/images/SPARK-4.png)

### Need for Apache Spark over Hadoop
![spark-hadoop-1](../assets/images/SPARK-3.png)
![hadoop](../assets/images/SPARK-15.png)
![spark](../assets/images/SPARK-16.png)
![spark-hadoop-2](../assets/images/SPARK-17.png)

## Components of Apache Spark

![spark-components](../assets/images/SPARK-5.png)
![spark-core](../assets/images/SPARK-6.png)

![spark-sql](../assets/images/SPARK-8.png)
![spark-ml](../assets/images/SPARK-9.png)
![spark-streaming](../assets/images/SPARK-10.png)
![spark-graph](../assets/images/SPARK-11.png)

![spark-clustermanager](../assets/images/SPARK-14.png)

# Apache Spark Architecture

![rdd](../assets/images/SPARK-7.png)
![spark-architecture-1](../assets/images/SPARK-12.png)
![spark-architecture-2](../assets/images/SPARK-13.png)
